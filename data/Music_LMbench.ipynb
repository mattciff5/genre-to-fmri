{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd \n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('amaai-lab/MusicBench', data_files=\"MusicBench_train_modified.json\")  \n",
    "# dataset = load_dataset('amaai-lab/MusicBench')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 15:20:56 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    }
   ],
   "source": [
    "from musiclm_pytorch import MuLaN, AudioSpectrogramTransformer, TextTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_transformer = AudioSpectrogramTransformer(\n",
    "    dim=512,\n",
    "    depth=6,\n",
    "    heads=8,\n",
    "    dim_head=64,\n",
    "    spec_n_fft=128,\n",
    "    spec_win_length=24,\n",
    "    spec_aug_stretch_factor=0.8\n",
    ")\n",
    "\n",
    "text_transformer = TextTransformer(\n",
    "    dim=512,\n",
    "    depth=6,\n",
    "    heads=8,\n",
    "    dim_head=64\n",
    ")\n",
    "\n",
    "mulan = MuLaN(\n",
    "    audio_transformer=audio_transformer,\n",
    "    text_transformer=text_transformer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset['train'], batch_size=64, shuffle=True, collate_fn=lambda x: x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'MusicBench',\n",
       " 'location': 'data_aug2/-0SdAVK79lg_1.wav',\n",
       " 'main_caption': 'This mellow instrumental track showcases a dominant electric guitar that opens with a descending riff, followed by arpeggiated chords, hammer-ons, and a slide. The percussion section keeps it simple with rim shots and a common time count, while the bass adds a single note on the first beat of every bar. Minimalist piano chords round out the song while leaving space for the guitar to shine. There are no vocals, making it perfect for a coffee shop or some chill background music. The key is in E major, with a chord progression that centers around that key and a straightforward 4/4 time signature.',\n",
       " 'alt_caption': 'This song features an electric guitar as the main instrument. The guitar plays a descending run in the beginning then plays an arpeggiated chord followed by a double stop hammer on to a higher note and a descending slide followed by a descending chord run. The percussion plays a simple beat using rim shots. The percussion plays in common time. The bass plays only one note on the first count of each bar. The piano plays backing chords. There are no voices in this song. The mood of this song is relaxing. This song can be played in a coffee shop. The key of this song is E major. The chord progression in this song is E. The beat counts to 4. ',\n",
       " 'prompt_aug': '',\n",
       " 'prompt_ch': 'The chord progression in this song is E.',\n",
       " 'prompt_bt': 'The beat counts to 4.',\n",
       " 'prompt_bpm': 'The bpm is 112.0.',\n",
       " 'prompt_key': 'The key of this song is E major.',\n",
       " 'beats': [[0.37212133669135816,\n",
       "   0.9070457581851855,\n",
       "   1.4652277632222228,\n",
       "   2.0234097682592598,\n",
       "   2.5583341897530874,\n",
       "   3.093258611246915,\n",
       "   3.628183032740742,\n",
       "   4.13984987069136,\n",
       "   4.6747742921851865,\n",
       "   5.232956297222224,\n",
       "   5.744623135172842,\n",
       "   6.326062723753089,\n",
       "   6.860987145246916,\n",
       "   7.372653983197533,\n",
       "   7.930835988234571,\n",
       "   8.442502826185187,\n",
       "   8.977427247679016,\n",
       "   9.535609252716052],\n",
       "  [4.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   3.0,\n",
       "   4.0,\n",
       "   1.0]],\n",
       " 'bpm': 112.0,\n",
       " 'chords': ['E'],\n",
       " 'chords_time': [0.5400400339790407],\n",
       " 'key': ['E', 'major'],\n",
       " 'keyprob': [0.8934084177017212],\n",
       " 'is_audioset_eval_mcaps': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('google/MusicCaps', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def download_clip(\n",
    "    video_identifier,\n",
    "    output_filename,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    tmp_dir='/tmp/musiccaps/',\n",
    "    num_attempts=5,\n",
    "    url_base='https://www.youtube.com/watch?v='\n",
    "):\n",
    "    status = False\n",
    "\n",
    "    command = f\"\"\"\n",
    "        yt-dlp --quiet --no-warnings -x --audio-format wav -f bestaudio -o \"{output_filename}\" --download-sections \"*{start_time}-{end_time}\" {url_base}{video_identifier}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    attempts = 0\n",
    "    while True:\n",
    "        try:\n",
    "            output = subprocess.check_output(command, shell=True,\n",
    "                                                stderr=subprocess.STDOUT)\n",
    "        except subprocess.CalledProcessError as err:\n",
    "            attempts += 1\n",
    "            if attempts == num_attempts:\n",
    "                return status, err.output\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Check if the video was successfully saved.\n",
    "    status = os.path.exists(output_filename)\n",
    "    return status, 'Downloaded'\n",
    "\n",
    "def process(example):\n",
    "    outfile_path = str(data_dir / f\"{example['ytid']}.wav\")\n",
    "    status = True\n",
    "    if not os.path.exists(outfile_path):\n",
    "        status = False\n",
    "        status, log = download_clip(\n",
    "            example['ytid'],\n",
    "            outfile_path,\n",
    "            example['start_s'],\n",
    "            example['end_s'],\n",
    "        )\n",
    "\n",
    "    example['audio'] = outfile_path\n",
    "    example['download_status'] = status\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 32/32 [00:30<00:00,  1.04 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "samples_to_load = 32      # How many samples to load\n",
    "cores = 4                 # How many processes to use for the loading\n",
    "sampling_rate = 44100     # Sampling rate for the audio, keep in 44100\n",
    "writer_batch_size = 1000  # How many examples to keep in memory per worker. Reduce if OOM.\n",
    "data_dir = \"./music_data\" # Where to save the data\n",
    "\n",
    "# Just select some samples \n",
    "ds = ds.select(range(samples_to_load))\n",
    "\n",
    "# Create directory where data will be saved\n",
    "data_dir = Path(data_dir)\n",
    "data_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "ds = ds.map(\n",
    "        process,\n",
    "        num_proc=cores,\n",
    "        writer_batch_size=writer_batch_size,\n",
    "        keep_in_memory=False\n",
    "    ).cast_column('audio', Audio(sampling_rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ytid': '-0Gj8-vB1q4',\n",
       " 'start_s': 30,\n",
       " 'end_s': 40,\n",
       " 'audioset_positive_labels': '/m/0140xf,/m/02cjck,/m/04rlf',\n",
       " 'aspect_list': \"['low quality', 'sustained strings melody', 'soft female vocal', 'mellow piano melody', 'sad', 'soulful', 'ballad']\",\n",
       " 'caption': 'The low quality recording features a ballad song that contains sustained strings, mellow piano melody and soft female vocal singing over it. It sounds sad and soulful, like something you would hear at Sunday services.',\n",
       " 'author_id': 4,\n",
       " 'is_balanced_subset': False,\n",
       " 'is_audioset_eval': True,\n",
       " 'audio': {'path': 'music_data/-0Gj8-vB1q4.wav',\n",
       "  'array': array([-2.98399059e-03, -3.63287400e-05,  2.31859041e-03, ...,\n",
       "         -1.94326155e-02, -2.38079876e-02,  0.00000000e+00]),\n",
       "  'sampling_rate': 44100},\n",
       " 'download_status': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-meg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
