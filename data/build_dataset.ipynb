{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from nilearn.plotting import plot_contrast_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_wav', 'ds003720', 'glmsingle_outputs']\n",
      "['brain2music-captions.csv', 'genres_original', '.DS_Store', 'features_30_sec.csv', 'images_original', 'features_3_sec.csv']\n",
      "['anat', 'func']\n"
     ]
    }
   ],
   "source": [
    "fmri_music_path = '/data01/data/fMRI_music_genre'\n",
    "print(os.listdir(fmri_music_path))\n",
    "stimuli_path = fmri_music_path + '/data_wav'\n",
    "print(os.listdir(stimuli_path))\n",
    "\n",
    "neural_path = fmri_music_path + '/ds003720/sub-001'\n",
    "print(os.listdir(neural_path))\n",
    "# fmri_data = nib.load(event_path_train.replace('events.tsv', 'bold.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub-001_task-Training_run-01_events.tsv', 'sub-001_task-Training_run-02_events.tsv', 'sub-001_task-Training_run-03_events.tsv', 'sub-001_task-Training_run-04_events.tsv', 'sub-001_task-Training_run-05_events.tsv', 'sub-001_task-Training_run-06_events.tsv', 'sub-001_task-Training_run-07_events.tsv', 'sub-001_task-Training_run-08_events.tsv', 'sub-001_task-Training_run-09_events.tsv', 'sub-001_task-Training_run-10_events.tsv', 'sub-001_task-Training_run-11_events.tsv', 'sub-001_task-Training_run-12_events.tsv']\n"
     ]
    }
   ],
   "source": [
    "def is_training_events_file(filename, phase):\n",
    "    return filename.startswith(\"sub-001_task-\"+phase+\"_run-\") and filename.endswith(\"_events.tsv\")\n",
    "\n",
    "all_files = os.listdir(neural_path + '/func')\n",
    "training_files = [filename for filename in all_files if is_training_events_file(filename, \"Training\")]\n",
    "print(training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 365.55it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 41/41 [00:00<00:00, 289.67it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 41/41 [00:00<00:00, 194.31it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 41/41 [00:00<00:00, 193.14it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 41/41 [00:00<00:00, 192.22it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 41/41 [00:00<00:00, 196.11it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 41/41 [00:00<00:00, 187.43it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 41/41 [00:00<00:00, 193.88it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 41/41 [00:00<00:00, 195.39it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 41/41 [00:00<00:00, 196.72it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 41/41 [00:00<00:00, 196.22it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 41/41 [00:00<00:00, 197.56it/s]\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/nilearn/glm/first_level/experimental_paradigm.py:167: UserWarning: The following unexpected columns in events data will be ignored: genre, end, track, start\n",
      "  warnings.warn(\n",
      "100%|██████████| 12/12 [02:10<00:00, 10.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 68, 492)\n",
      "(240000, 492)\n"
     ]
    }
   ],
   "source": [
    "def get_fmri_data(training_files, t_r):\n",
    "    eff_map_arrays = []\n",
    "    stimuli_arrays = []\n",
    "    for event in tqdm(training_files):\n",
    "        event_path = neural_path + '/func/' + event\n",
    "        events_df = pd.read_csv(event_path, sep='\\t')\n",
    "\n",
    "        for i in tqdm(range(len(events_df))):\n",
    "            genre = events_df['genre'].iloc[i].strip(\"'\")\n",
    "            track = int(events_df['track'].iloc[i]) \n",
    "            start = float(events_df['start'].iloc[i])\n",
    "            track_str = str(track).zfill(5) \n",
    "            wav_path = os.path.join(stimuli_path, 'genres_original', genre, f\"{genre}.{track_str}.wav\")\n",
    "            y_sound, sr = librosa.load(wav_path, sr=16000, offset=start, duration=15)\n",
    "            stimuli_arrays.append(y_sound.reshape(-1,1))\n",
    "\n",
    "        fmri_img = nib.load(event_path.replace('events.tsv', 'bold.nii'))\n",
    "        events_df['trial_type'] = events_df['genre'].str.strip(\"'\") + ' - ' + events_df['track'].astype(str)\n",
    "        first_level_model = FirstLevelModel(t_r)\n",
    "        first_level_model = first_level_model.fit(fmri_img, events=events_df)\n",
    "        design_matrix_gentrack = first_level_model.design_matrices_[0]\n",
    "\n",
    "        contrast_val_gentrack = np.eye(design_matrix_gentrack.shape[1])[0:-13]\n",
    "        eff_map_gentrack = first_level_model.compute_contrast(contrast_val_gentrack, output_type=\"effect_size\")\n",
    "        data_gentrack = eff_map_gentrack.get_fdata()\n",
    "        eff_map_arrays.append(data_gentrack)\n",
    "\n",
    "    eff_map_stacked = np.concatenate(eff_map_arrays, axis=-1)\n",
    "    stimuli_stacked = np.concatenate(stimuli_arrays, axis=-1)\n",
    "    return eff_map_stacked, stimuli_stacked\n",
    "\n",
    "eff_map_stacked, stimuli_stacked = get_fmri_data(training_files, 1.5)\n",
    "print(eff_map_stacked.shape)\n",
    "print(stimuli_stacked.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "disco\n",
      "9\n",
      "4.21\n",
      "00009\n",
      "/data01/data/fMRI_music_genre/data_wav/genres_original/disco/disco.00009.wav\n",
      "(240000, 1)\n"
     ]
    }
   ],
   "source": [
    "event_path = neural_path + '/func/' + training_files[0]\n",
    "events_df = pd.read_csv(event_path, sep='\\t')\n",
    "print(len(events_df))\n",
    "genre = events_df['genre'].iloc[0].strip(\"'\") \n",
    "print(genre)\n",
    "track = int(events_df['track'].iloc[0])\n",
    "print(track)\n",
    "start = float(events_df['start'].iloc[0])\n",
    "print(start)\n",
    "track_str = str(track).zfill(5)  \n",
    "print(track_str)\n",
    "get_path = os.path.join(stimuli_path, 'genres_original', genre, f\"{genre}.{track_str}.wav\")\n",
    "print(get_path)\n",
    "y, sr = librosa.load(get_path, sr=16000, offset=start, duration=15)\n",
    "print(y.reshape(-1,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def construct_wav_path(row):\n",
    "#     genre = row['genre'].strip(\"'\")  \n",
    "#     track = int(row['track'])\n",
    "#     track_str = str(track).zfill(5)  \n",
    "#     return os.path.join(base_directory, genre, f\"{genre}.{track_str}.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-meg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
